{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e75f462-047e-4638-bc41-7750e1316dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninputフォルダに圧縮済みデータをダウンロード(dicom->png)\\nhttps://www.kaggle.com/jonathanbesomi/rsna-miccai-png\\n\\nローカルにダウンロードする場合は、5GBほどなので専用ツールなどで解凍する（swindows:7zipなど）\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "inputフォルダに圧縮済みデータをダウンロード(dicom->png)\n",
    "https://www.kaggle.com/jonathanbesomi/rsna-miccai-png\n",
    "\n",
    "ローカルにダウンロードする場合は、5GBほどなので専用ツールなどで解凍する（swindows:7zipなど）\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c5348c6-7a88-41cb-8534-6d4ba6ccf8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ドライブ C のボリューム ラベルは OS です\n",
      " ボリューム シリアル番号は 1EE5-A2C9 です\n",
      "\n",
      " C:\\Users\\muson\\Desktop\\pycharm\\pytorch_advanced\\BrainTumorClass のディレクトリ\n",
      "\n",
      "2021/08/15  18:14    <DIR>          .\n",
      "2021/08/15  18:14    <DIR>          ..\n",
      "2021/08/15  00:39    <DIR>          .ipynb_checkpoints\n",
      "2021/08/15  18:14            23,524 BrainTumorClass.ipynb\n",
      "2021/08/15  18:09    <DIR>          input\n",
      "2021/08/14  23:59    <DIR>          model\n",
      "2021/08/14  23:59    <DIR>          output\n",
      "2021/08/14  23:59    <DIR>          weight\n",
      "               1 個のファイル              23,524 バイト\n",
      "               7 個のディレクトリ  289,043,181,568 バイトの空き領域\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8faa7d1a-7c68-4761-9e6e-236809cfdae5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydicom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;34mC:\\Users\\muson\\anaconda3\\envs\\py37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m, in \u001b[0;32mrun_code\u001b[0m:\nLine \u001b[0;34m3437\u001b[0m:  exec(code_obj, \u001b[36mself\u001b[39;49;00m.user_global_ns, \u001b[36mself\u001b[39;49;00m.user_ns)\n",
      "In  \u001b[0;34m[6]\u001b[0m:\nLine \u001b[0;34m12\u001b[0m:    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpydicom\u001b[39;49;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydicom'\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "## 必要ライブラリのimport\n",
    "import os\n",
    "import sys \n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data as torch_data\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "from torch.nn import functional as torch_functional\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e159e6a1-9587-4f5c-ab62-172c61196a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input変数作成\n",
    "if os.path.exists(\"input/rsna-miccai-png\"):\n",
    "    data_directory = 'input/rsna-miccai-png'\n",
    "    pytorch3dpath = \"input/EfficientNet-PyTorch-3D\"\n",
    "else:\n",
    "    raise ValueError(\"please locate data in input folder\")\n",
    "    \n",
    "mri_types = ['FLAIR','T1w','T1wCE','T2w']\n",
    "SIZE = 256\n",
    "NUM_IMAGES = 64\n",
    "\n",
    "sys.path.append(pytorch3dpath)\n",
    "from efficientnet_pytorch_3d import EfficientNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfdf969-a9e0-42c1-a602-58fc191ab5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_png_image(path, img_size=SIZE, voi_lut=True, rotate=0):\n",
    "    data = cv2.imread()\n",
    "    if rotate > 0:\n",
    "        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
    "        data = cv2.rotate(data, rot_choices[rotate])\n",
    "    data = cv2.resize(data, (img_size, img_size))\n",
    "    return data\n",
    "    \n",
    "def load_png_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\", rotate=0):\n",
    "\n",
    "    files = sorted(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"), \n",
    "               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "\n",
    "    middle = len(files)//2\n",
    "    num_imgs2 = num_imgs//2\n",
    "    p1 = max(0, middle - num_imgs2)\n",
    "    p2 = min(len(files), middle + num_imgs2)\n",
    "    img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n",
    "    if img3d.shape[-1] < num_imgs:\n",
    "        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n",
    "        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n",
    "        \n",
    "    if np.min(img3d) < np.max(img3d):\n",
    "        img3d = img3d - np.min(img3d)\n",
    "        img3d = img3d / np.max(img3d)\n",
    "            \n",
    "    return np.expand_dims(img3d,0)\n",
    "\n",
    "\n",
    "def load_dicom_image(path, img_size=SIZE, voi_lut=True, rotate=0):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "        \n",
    "    if rotate > 0:\n",
    "        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
    "        data = cv2.rotate(data, rot_choices[rotate])\n",
    "        \n",
    "    data = cv2.resize(data, (img_size, img_size))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\", rotate=0):\n",
    "\n",
    "    files = sorted(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"), \n",
    "               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "\n",
    "    middle = len(files)//2\n",
    "    num_imgs2 = num_imgs//2\n",
    "    p1 = max(0, middle - num_imgs2)\n",
    "    p2 = min(len(files), middle + num_imgs2)\n",
    "    img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n",
    "    if img3d.shape[-1] < num_imgs:\n",
    "        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n",
    "        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n",
    "        \n",
    "    if np.min(img3d) < np.max(img3d):\n",
    "        img3d = img3d - np.min(img3d)\n",
    "        img3d = img3d / np.max(img3d)\n",
    "            \n",
    "    return np.expand_dims(img3d,0)\n",
    "\n",
    "# a = load_dicom_images_3d(\"00000\")\n",
    "# print(a.shape)\n",
    "# print(np.min(a), np.max(a), np.mean(a), np.median(a))\n",
    "\n",
    "a = load_png_images_3d(\"00000\")\n",
    "print(a.shape)\n",
    "print(np.min(a), np.max(a), np.mean(a), np.median(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575d0ec-180b-4651-bdcb-1bead3a23a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81962f-73b9-4d53-97da-ce739360d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split train & validation data\n",
    "train_df = pd.read_csv(f\"{data_directory}/train_labels.csv\")\n",
    "display(train_df)\n",
    "\n",
    "df_train, df_valid = sk_model_selection.train_test_split(\n",
    "    train_df, \n",
    "    test_size=0.2, \n",
    "    random_state=12, \n",
    "    stratify=train_df[\"MGMT_value\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2ac97b-600c-4563-a39b-e0144d78d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "## weightフォルダにpretrained weightをダウンロード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78237248-f4bc-423b-bd20-a68b4933fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataSetの作成\n",
    "## DataTransformerの作成\n",
    "class Dataset(torch_data.Dataset):\n",
    "    def __init__(self, paths, targets=None, mri_type=None, label_smoothing=0.01, split=\"train\", augment=False):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "        self.mri_type = mri_type\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.split = split\n",
    "        self.augment = augment\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        scan_id = self.paths[index]\n",
    "        if self.targets is None:\n",
    "            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split)\n",
    "        else:\n",
    "            if self.augment:\n",
    "                rotation = np.random.randint(0,4)\n",
    "            else:\n",
    "                rotation = 0\n",
    "\n",
    "            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\", rotate=rotation)\n",
    "\n",
    "        if self.targets is None:\n",
    "            return {\"X\": torch.tensor(data).float(), \"id\": scan_id}\n",
    "        else:\n",
    "            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n",
    "            return {\"X\": torch.tensor(data).float(), \"y\": y}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f669b-e6e2-4f25-9280-de5e4bfc69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef33720-4c88-4f24-a389-7df917c36495",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modelの作成\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n",
    "        n_features = self.net._fc.in_features\n",
    "        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af923a7c-43e1-44de-ad31-e838b31c47a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.best_valid_score = np.inf\n",
    "        self.n_patience = 0\n",
    "        self.lastmodel = None\n",
    "        \n",
    "    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message(\"EPOCH: {}\", n_epoch)\n",
    "            \n",
    "            train_loss, train_time = self.train_epoch(train_loader)\n",
    "            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s            \",\n",
    "                n_epoch, train_loss, train_time\n",
    "            )\n",
    "            \n",
    "            self.info_message(\n",
    "                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n",
    "                n_epoch, valid_loss, valid_auc, valid_time\n",
    "            )\n",
    "\n",
    "            # if True:\n",
    "            # if self.best_valid_score < valid_auc: \n",
    "            if self.best_valid_score > valid_loss: \n",
    "                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n",
    "                self.info_message(\n",
    "                     \"auc improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n",
    "                    self.best_valid_score, valid_loss, self.lastmodel\n",
    "                )\n",
    "                self.best_valid_score = valid_loss\n",
    "                self.n_patience = 0\n",
    "            else:\n",
    "                self.n_patience += 1\n",
    "            \n",
    "            if self.n_patience >= patience:\n",
    "                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n",
    "                break\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "\n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            X = batch[\"X\"].to(self.device)\n",
    "            targets = batch[\"y\"].to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(X).squeeze(1)\n",
    "            \n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            sum_loss += loss.detach().item()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            message = 'Train Step {}/{}, train_loss: {:.4f}'\n",
    "            self.info_message(message, step, len(train_loader), sum_loss/step, end=\"\\r\")\n",
    "        \n",
    "        return sum_loss/len(train_loader), int(time.time() - t)\n",
    "    \n",
    "    def valid_epoch(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        sum_loss = 0\n",
    "        y_all = []\n",
    "        outputs_all = []\n",
    "\n",
    "        for step, batch in enumerate(valid_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                X = batch[\"X\"].to(self.device)\n",
    "                targets = batch[\"y\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(X).squeeze(1)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                sum_loss += loss.detach().item()\n",
    "                y_all.extend(batch[\"y\"].tolist())\n",
    "                outputs_all.extend(outputs.tolist())\n",
    "\n",
    "            message = 'Valid Step {}/{}, valid_loss: {:.4f}'\n",
    "            self.info_message(message, step, len(valid_loader), sum_loss/step, end=\"\\r\")\n",
    "            \n",
    "        y_all = [1 if x > 0.5 else 0 for x in y_all]\n",
    "        auc = roc_auc_score(y_all, outputs_all)\n",
    "        \n",
    "        return sum_loss/len(valid_loader), auc, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_path, loss, auc):\n",
    "        self.lastmodel = f\"{save_path}-e{n_epoch}-loss{loss:.3f}-auc{auc:.3f}.pth\"\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"best_valid_score\": self.best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            self.lastmodel,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end=\"\\n\"):\n",
    "        print(message.format(*args), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf1cbe-8608-4c77-99b6-abd9c838a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DataLoaderの作成\n",
    "## 損失関数、optimizer作成\n",
    "## 学習\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_mri_type(df_train, df_valid, mri_type):\n",
    "    if mri_type==\"all\":\n",
    "        train_list = []\n",
    "        valid_list = []\n",
    "        for mri_type in mri_types:\n",
    "            df_train.loc[:,\"MRI_Type\"] = mri_type\n",
    "            train_list.append(df_train.copy())\n",
    "            df_valid.loc[:,\"MRI_Type\"] = mri_type\n",
    "            valid_list.append(df_valid.copy())\n",
    "\n",
    "        df_train = pd.concat(train_list)\n",
    "        df_valid = pd.concat(valid_list)\n",
    "    else:\n",
    "        df_train.loc[:,\"MRI_Type\"] = mri_type\n",
    "        df_valid.loc[:,\"MRI_Type\"] = mri_type\n",
    "\n",
    "    print(df_train.shape, df_valid.shape)\n",
    "    display(df_train.head())\n",
    "    \n",
    "    train_data_retriever = Dataset(\n",
    "        df_train[\"BraTS21ID\"].values, \n",
    "        df_train[\"MGMT_value\"].values, \n",
    "        df_train[\"MRI_Type\"].values,\n",
    "        augment=True\n",
    "    )\n",
    "\n",
    "    valid_data_retriever = Dataset(\n",
    "        df_valid[\"BraTS21ID\"].values, \n",
    "        df_valid[\"MGMT_value\"].values,\n",
    "        df_valid[\"MRI_Type\"].values\n",
    "    )\n",
    "\n",
    "    train_loader = torch_data.DataLoader(\n",
    "        train_data_retriever,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "    )\n",
    "\n",
    "    valid_loader = torch_data.DataLoader(\n",
    "        valid_data_retriever, \n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "    )\n",
    "\n",
    "    model = Model()\n",
    "    model.to(device)\n",
    "\n",
    "    #checkpoint = torch.load(\"best-model-all-auc0.555.pth\")\n",
    "    #model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "    #print(model)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    criterion = torch_functional.binary_cross_entropy_with_logits\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion\n",
    "    )\n",
    "\n",
    "    history = trainer.fit(\n",
    "        10, \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        f\"{mri_type}\", \n",
    "        10,\n",
    "    )\n",
    "    \n",
    "    return trainer.lastmodel\n",
    "\n",
    "modelfiles = None\n",
    "\n",
    "if not modelfiles:\n",
    "    modelfiles = [train_mri_type(df_train, df_valid, m) for m in mri_types]\n",
    "    print(modelfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680289c8-291e-4107-9231-9221eaaaf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 推論\n",
    "def predict(modelfile, df, mri_type, split):\n",
    "    print(\"Predict:\", modelfile, mri_type, df.shape)\n",
    "    df.loc[:,\"MRI_Type\"] = mri_type\n",
    "    data_retriever = Dataset(\n",
    "        df.index.values, \n",
    "        mri_type=df[\"MRI_Type\"].values,\n",
    "        split=split\n",
    "    )\n",
    "\n",
    "    data_loader = torch_data.DataLoader(\n",
    "        data_retriever,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "    )\n",
    "   \n",
    "    model = Model()\n",
    "    model.to(device)\n",
    "    \n",
    "    checkpoint = torch.load(modelfile)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    y_pred = []\n",
    "    ids = []\n",
    "\n",
    "    for e, batch in enumerate(data_loader,1):\n",
    "        print(f\"{e}/{len(data_loader)}\", end=\"\\r\")\n",
    "        with torch.no_grad():\n",
    "            tmp_pred = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n",
    "            if tmp_pred.size == 1:\n",
    "                y_pred.append(tmp_pred)\n",
    "            else:\n",
    "                y_pred.extend(tmp_pred.tolist())\n",
    "            ids.extend(batch[\"id\"].numpy().tolist())\n",
    "            \n",
    "    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n",
    "    preddf = preddf.set_index(\"BraTS21ID\")\n",
    "    return preddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64647fa8-6b1f-4c4f-9eb7-840fc1e898be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##　各モデルをアンサンブル\n",
    "df_valid = df_valid.set_index(\"BraTS21ID\")\n",
    "df_valid[\"MGMT_pred\"] = 0\n",
    "for m, mtype in zip(modelfiles,  mri_types):\n",
    "    pred = predict(m, df_valid, mtype, \"train\")\n",
    "    df_valid[\"MGMT_pred\"] += pred[\"MGMT_value\"]\n",
    "df_valid[\"MGMT_pred\"] /= len(modelfiles)\n",
    "auc = roc_auc_score(df_valid[\"MGMT_value\"], df_valid[\"MGMT_pred\"])\n",
    "print(f\"Validation ensemble AUC: {auc:.4f}\")\n",
    "sns.displot(df_valid[\"MGMT_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011b918-d871-40a9-bf0a-9d9e8ca7a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## outputフォルダにsubmission csvを格納\n",
    "submission = pd.read_csv(f\"{data_directory}/sample_submission.csv\", index_col=\"BraTS21ID\")\n",
    "\n",
    "submission[\"MGMT_value\"] = 0\n",
    "for m, mtype in zip(modelfiles, mri_types):\n",
    "    pred = predict(m, submission, mtype, split=\"test\")\n",
    "    submission[\"MGMT_value\"] += pred[\"MGMT_value\"]\n",
    "\n",
    "submission[\"MGMT_value\"] /= len(modelfiles)\n",
    "submission[\"MGMT_value\"].to_csv(\"submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80ae15-a5a2-4095-814d-d752d740c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa3492-14d6-49cf-ac17-3c01873218ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(submission[\"MGMT_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5835c3-10aa-4687-884f-7ff84b78db33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
